{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 22:12:33.101150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-19 22:12:33.380407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:33.380419: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-19 22:12:33.416913: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-19 22:12:34.232642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:34.232803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:34.232808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from methods import *\n",
    "from numpy.random import seed\n",
    "from keras import backend as K\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "seed(0)\n",
    "\n",
    "################################\n",
    "#### get dense layer output ####\n",
    "################################\n",
    "\n",
    "#getting the x and y inputs in numpy array form from the text file\n",
    "def train_x(train_txt, word2vec_len, input_size, word2vec):\n",
    "\n",
    "\t#read in lines\n",
    "\ttrain_lines = open(train_txt, 'r').readlines()\n",
    "\tnum_lines = len(train_lines)\n",
    "\n",
    "\tx_matrix = np.zeros((num_lines, input_size, word2vec_len))\n",
    "\n",
    "\t#insert values\n",
    "\tfor i, line in enumerate(train_lines):\n",
    "\n",
    "\t\tparts = line[:-1].split('\\t')\n",
    "\t\tlabel = int(parts[0])\n",
    "\t\tsentence = parts[1]\t\n",
    "\n",
    "\t\t#insert x\n",
    "\t\twords = sentence.split(' ')\n",
    "\t\twords = words[:x_matrix.shape[1]] #cut off if too long\n",
    "\t\tfor j, word in enumerate(words):\n",
    "\t\t\tif word in word2vec:\n",
    "\t\t\t\tx_matrix[i, j, :] = word2vec[word]\n",
    "\n",
    "\treturn x_matrix\n",
    "\n",
    "def get_dense_output(model_checkpoint, file, num_classes):\n",
    "\n",
    "\tx = train_x(file, word2vec_len, input_size, word2vec)\n",
    "\n",
    "\tmodel = load_model(model_checkpoint)\n",
    "\n",
    "\tget_3rd_layer_output = K.function([model.layers[0].input], [model.layers[3].output])\n",
    "\tlayer_output = get_3rd_layer_output([x])[0]\n",
    "\n",
    "\treturn layer_output\n",
    "\n",
    "def get_tsne_labels(file):\n",
    "\tlabels = []\n",
    "\talphas = []\n",
    "\tlines = open(file, 'r').readlines()\n",
    "\tfor i, line in enumerate(lines):\n",
    "\t\tparts = line[:-1].split('\\t')\n",
    "\t\t_class = int(parts[0])\n",
    "\t\talpha = i % 10\n",
    "\t\tif alpha == 0:\n",
    "\t\t\tlabels.append(_class+100)\n",
    "\t\t\talphas.append(alpha)\n",
    "\t\telse:\n",
    "\t\t\tlabels.append(_class)\n",
    "\t\t\talphas.append(alpha)\n",
    "\treturn labels, alphas\n",
    "\n",
    "def get_plot_vectors(layer_output):\n",
    "\n",
    "\ttsne = TSNE(n_components=2,perplexity=10).fit_transform(layer_output)\n",
    "\treturn tsne\n",
    "\n",
    "def plot_tsne(tsne, labels, output_path):\n",
    "\n",
    "\tlabel_to_legend_label = {'output/cr_tsne.png':{\t0:'Con (augmented)', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t100:'Con (original)', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t1: 'Pro (augmented)', \n",
    "\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t101:'Pro (original)'}}\n",
    "\t\t\t\t\t\t\t\t# 'outputs_f4/trec_tsne.png':{0:'Description (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t100:'Description (original)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t1:'Entity (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t101:'Entity (original)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t2:'Abbreviation (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t102:'Abbreviation (original)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t3:'Human (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t103:'Human (original)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t4:'Location (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t104:'Location (original)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t5:'Number (augmented)',\n",
    "\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t105:'Number (original)'}}\n",
    "\n",
    "\tplot_to_legend_size = {'output/cr_tsne.png':11}\n",
    "\n",
    "\tlabels = labels#.tolist() \n",
    "\tbig_groups = [label for label in labels if label < 100]\n",
    "\tbig_groups = list(sorted(set(big_groups)))\n",
    "\n",
    "\tcolors = ['b', 'g']#, 'r', 'c', 'm', 'y', 'k', '#ff1493', '#FF4500']\n",
    "\tfig, ax = plt.subplots()\n",
    "\n",
    "\tfor big_group in big_groups:\n",
    "\n",
    "\t\tfor group in [big_group, big_group+100]:\n",
    "\n",
    "\t\t\tx, y = [], []\n",
    "\n",
    "\t\t\tfor j, label in enumerate(labels):\n",
    "\t\t\t\tif label == group:\n",
    "\t\t\t\t\tx.append(tsne[j][0])\n",
    "\t\t\t\t\ty.append(tsne[j][1])\n",
    "\n",
    "\t\t\t#params\n",
    "\t\t\tcolor = colors[int(group % 100)]\n",
    "\t\t\tmarker = 'o' if group in[0,100] else '^'\n",
    "\t\t\tsize = 1 if group < 100 else 27\t\t\n",
    "\t\t\tfillstyles = color if group < 100 else 'none'\n",
    "\n",
    "\t\t\tlegend_label = label_to_legend_label[output_path][group]\n",
    "\n",
    "\t\t\tax.scatter(x, y, color=color, marker=marker, s=size, facecolors=fillstyles, label=legend_label)\n",
    "\t\t\tplt.axis('off')\n",
    "\n",
    "\tlegend_size = plot_to_legend_size[output_path]\n",
    "\tplt.legend(prop={'size': legend_size})\n",
    "\tplt.savefig(output_path, dpi=1000)\n",
    "\tplt.clf()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "#global variables\n",
    "word2vec_len = 300\n",
    "input_size = 20\n",
    "\n",
    "datasets = ['cr'] #['pc', 'trec']\n",
    "num_classes_list =[2] #[2, 6]\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "\n",
    "    #load parameters\n",
    "    model_checkpoint = 'output/' + dataset + '.h5'\n",
    "    file = 'txt_for_test/' + dataset + '/test_aug.txt'\n",
    "    num_classes = num_classes_list[i]\n",
    "    word2vec_pickle = 'txt_for_test/' + dataset + '/word2vec.p'\n",
    "    word2vec = load_pickle(word2vec_pickle)\n",
    "\n",
    "    #do tsne\n",
    "    layer_output = get_dense_output(model_checkpoint, file, num_classes)\n",
    "    #print(layer_output.shape)\n",
    "    t = get_plot_vectors(layer_output)\n",
    "\n",
    "    # use plotly just to compare with the original plot from eda\n",
    "    labels, alphas = get_tsne_labels(file)\n",
    "    # projections = TSNE(n_components=2).fit_transform(layer_output)\n",
    "    # fig = px.scatter(projections, x=0, y=1, color= labels, size= labels,labels={'color':'label'})\n",
    "    # fig.show()\n",
    "    #print(labels, alphas)\n",
    "\n",
    "    writer = open(\"output/new_tsne.txt\", 'w')\n",
    "\n",
    "    label_to_mark = {0:'o', 1:'^',100:'o', 101:'^'}\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        alpha = alphas[i]\n",
    "        line = str(t[i, 0]) + ' ' + str(t[i, 1]) + ' ' + str(label_to_mark[label]) + ' ' + str(alpha/10)\n",
    "        writer.write(line + '\\n')\n",
    "    plot_tsne(t, labels, 'output/' + dataset + '_tsne.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(layer_number,input_size,perplexity,n_iter):\n",
    "    def train_x(train_txt, word2vec_len, input_size, word2vec):\n",
    "\n",
    "        #read in lines\n",
    "        train_lines = open(train_txt, 'r').readlines()\n",
    "        num_lines = len(train_lines)\n",
    "\n",
    "        x_matrix = np.zeros((num_lines, input_size, word2vec_len))\n",
    "\n",
    "        #insert values\n",
    "        for i, line in enumerate(train_lines):\n",
    "\n",
    "            parts = line[:-1].split('\\t')\n",
    "            label = int(parts[0])\n",
    "            sentence = parts[1]\t\n",
    "\n",
    "            #insert x\n",
    "            words = sentence.split(' ')\n",
    "            words = words[:x_matrix.shape[1]] #cut off if too long\n",
    "            for j, word in enumerate(words):\n",
    "                if word in word2vec:\n",
    "                    x_matrix[i, j, :] = word2vec[word]\n",
    "\n",
    "        return x_matrix\n",
    "\n",
    "    def get_dense_output(model_checkpoint, file, num_classes):\n",
    "\n",
    "        x = train_x(file, word2vec_len, input_size, word2vec)\n",
    "\n",
    "        model = load_model(model_checkpoint)\n",
    "\n",
    "        get_3rd_layer_output = K.function([model.layers[0].input], [model.layers[layer_number].output])\n",
    "        layer_output = get_3rd_layer_output([x])[0]\n",
    "\n",
    "        return layer_output\n",
    "\n",
    "    def get_tsne_labels(file):\n",
    "        labels = []\n",
    "        alphas = []\n",
    "        lines = open(file, 'r').readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            parts = line[:-1].split('\\t')\n",
    "            _class = int(parts[0])\n",
    "            alpha = i % 10\n",
    "            if alpha == 0:\n",
    "                labels.append(_class+100)\n",
    "                alphas.append(alpha)\n",
    "            else:\n",
    "                labels.append(_class)\n",
    "                alphas.append(alpha)\n",
    "        return labels, alphas\n",
    "\n",
    "    def get_plot_vectors(layer_output):\n",
    "\n",
    "        tsne = TSNE(n_components=2,perplexity=perplexity,n_iter=n_iter).fit_transform(layer_output)\n",
    "        return tsne\n",
    "\n",
    "    def plot_tsne(tsne, labels):\n",
    "        output_path = f'output/tsne/{dataset}_tsne_perplexity_{perplexity}__iteration_{n_iter}__layerNum_{layer_number}__inputSize_{input_size}.png'\n",
    "\n",
    "        label_to_legend_label = {output_path:{\t0:'Con (augmented)', \n",
    "                                                                100:'Con (original)', \n",
    "                                                                1: 'Pro (augmented)', \n",
    "                                                                101:'Pro (original)'}}\n",
    "                                    # 'outputs_f4/trec_tsne.png':{0:'Description (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t100:'Description (original)',\n",
    "                                    # \t\t\t\t\t\t\t1:'Entity (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t101:'Entity (original)',\n",
    "                                    # \t\t\t\t\t\t\t2:'Abbreviation (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t102:'Abbreviation (original)',\n",
    "                                    # \t\t\t\t\t\t\t3:'Human (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t103:'Human (original)',\n",
    "                                    # \t\t\t\t\t\t\t4:'Location (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t104:'Location (original)',\n",
    "                                    # \t\t\t\t\t\t\t5:'Number (augmented)',\n",
    "                                    # \t\t\t\t\t\t\t105:'Number (original)'}}\n",
    "\n",
    "        plot_to_legend_size = {output_path:11}\n",
    "\n",
    "        labels = labels#.tolist() \n",
    "        big_groups = [label for label in labels if label < 100]\n",
    "        big_groups = list(sorted(set(big_groups)))\n",
    "\n",
    "        colors = ['b', 'g']#, 'r', 'c', 'm', 'y', 'k', '#ff1493', '#FF4500']\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for big_group in big_groups:\n",
    "\n",
    "            for group in [big_group, big_group+100]:\n",
    "\n",
    "                x, y = [], []\n",
    "\n",
    "                for j, label in enumerate(labels):\n",
    "                    if label == group:\n",
    "                        x.append(tsne[j][0])\n",
    "                        y.append(tsne[j][1])\n",
    "\n",
    "                #params\n",
    "                color = colors[int(group % 100)]\n",
    "                marker = 'o' if group in[0,100] else '^'\n",
    "                size = 1 if group < 100 else 27\t\t\n",
    "                fillstyles = color if group < 100 else 'none'\n",
    "\n",
    "                legend_label = label_to_legend_label[output_path][group]\n",
    "\n",
    "                ax.scatter(x, y, color=color, marker=marker, s=size, facecolors=fillstyles, label=legend_label)\n",
    "                plt.axis('off')\n",
    "\n",
    "        legend_size = plot_to_legend_size[output_path]\n",
    "        plt.legend(prop={'size': legend_size})\n",
    "        plt.savefig(output_path, dpi=1000)\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "\n",
    "        #load parameters\n",
    "        model_checkpoint = 'output/' + dataset + '.h5'\n",
    "        file = 'txt_for_test/' + dataset + '/test_aug.txt'\n",
    "        num_classes = num_classes_list[i]\n",
    "        word2vec_pickle = 'txt_for_test/' + dataset + '/word2vec.p'\n",
    "        word2vec = load_pickle(word2vec_pickle)\n",
    "\n",
    "        #do tsne\n",
    "        layer_output = get_dense_output(model_checkpoint, file, num_classes)\n",
    "        #print(layer_output.shape)\n",
    "        t = get_plot_vectors(layer_output)\n",
    "\n",
    "        # use plotly just to compare with the original plot from eda\n",
    "        labels, alphas = get_tsne_labels(file)\n",
    "        # projections = TSNE(n_components=2).fit_transform(layer_output)\n",
    "        # fig = px.scatter(projections, x=0, y=1, color= labels, size= labels,labels={'color':'label'})\n",
    "        # fig.show()\n",
    "        #print(labels, alphas)\n",
    "\n",
    "        #writer = open(\"output/new_tsne.txt\", 'w')\n",
    "\n",
    "        #label_to_mark = {0:'o', 1:'^',100:'o', 101:'^'}\n",
    "\n",
    "        # for i, label in enumerate(labels):\n",
    "        #     alpha = alphas[i]\n",
    "        #     line = str(t[i, 0]) + ' ' + str(t[i, 1]) + ' ' + str(label_to_mark[label]) + ' ' + str(alpha/10)\n",
    "        #     writer.write(line + '\\n')\n",
    "        plot_tsne(t, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]2022-10-19 22:12:45.002429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 22:12:45.002931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-19 22:12:45.003546: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-19 22:12:45.004137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-19 22:12:45.692743: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3483600000 exceeds 10% of free system memory.\n",
      "2022-10-19 22:12:46.803105: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1741800000 exceeds 10% of free system memory.\n",
      "2022-10-19 22:12:46.998104: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1741800000 exceeds 10% of free system memory.\n",
      "2022-10-19 22:12:49.003992: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1741800000 exceeds 10% of free system memory.\n",
      "2022-10-19 22:12:49.164570: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1741800000 exceeds 10% of free system memory.\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/peyman/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "word2vec_len = 300\n",
    "input_size = 25\n",
    "datasets = ['pc'] \n",
    "num_classes_list = [2] \n",
    "layer_number = 4\n",
    "perplexity = [20,30,40,50,60]\n",
    "n_iter = [1000,2000,3000,4000,5000]\n",
    "\n",
    "for j in tqdm(perplexity):\n",
    "    for k in tqdm(n_iter):\n",
    "        tsne(layer_number,input_size,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "105d983fd7af724b4799aa016a3246070456ed2a0f153d4c18e29a0780e65f60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
