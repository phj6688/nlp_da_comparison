{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.augmentation import \\\n",
    "    EasyDataAugmenter, BackTranslationAugmenter, WordNetAugmenter, CLAREAugmenter, \\\n",
    "    CheckListAugmenter, EmbeddingAugmenter, DeletionAugmenter, CharSwapAugmenter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/student/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/student/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "eda_augmenter = EasyDataAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "wordnet_augmenter = WordNetAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "clare_augmenter = CLAREAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "backtranslation_augmenter = BackTranslationAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "checklist_augmenter = CheckListAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "embedding_augmenter = EmbeddingAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "deletion_augmenter = DeletionAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "charswap_augmenter = CharSwapAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n",
    "#list_of_augmenters = [eda_augmenter, wordnet_augmenter, clare_augmenter, backtranslation_augmenter, deletion_augmenter]\n",
    "\n",
    "list_of_augmenters = [eda_augmenter, wordnet_augmenter, clare_augmenter, backtranslation_augmenter, checklist_augmenter, embedding_augmenter, deletion_augmenter, charswap_augmenter]\n",
    "sentence = 'What I cannot create, I do not understand.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EasyDataAugmenter\n",
      "['What I cannot create, I do not non understand.', 'What I cannot create, I not understand.', 'What one cannot create, I do not understand.', 'create I cannot What, I do not understand.']\n",
      "WordNetAugmenter\n",
      "['What 1 cannot create, I do not understand.', 'What I cannot create, I do not read.', 'What I cannot create, I do not realise.', 'What I cannot create, single do not understand.']\n",
      "CLAREAugmenter\n",
      "2022-08-29 14:53:02,945 loading file /home/student/.flair/models/upos-english-fast/b631371788604e95f27b6567fe7220e4a7e8d03201f3d862e6204dbf90f9f164.0afb95b43b32509bf4fcc3687f7c64157d8880d08f813124c1bd371c3d8ee3f7\n",
      "2022-08-29 14:53:03,035 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, INTJ, PUNCT, VERB, PRON, NOUN, ADV, DET, ADJ, ADP, NUM, PROPN, CCONJ, PART, AUX, X, SYM, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 14:53:03.256035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-29 14:53:03.256643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-29 14:53:03.256650: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-29 14:53:03.256761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What I cannot create, I completely do not understand.', 'What I cannot create, I do not enjoy.', 'What I cannot tolerate, I do not understand.', 'What content I cannot create, I do not understand.']\n",
      "BackTranslationAugmenter\n",
      "[\"I don't understand what I can't create.\", \"That I can't create, I don't mean.\", \"What I can't create, I don't understand.\", \"What he can't create, he doesn't understand.\"]\n",
      "CheckListAugmenter\n",
      "['What I cannot create, I do not understand.', \"What I cannot create, I don't understand.\"]\n",
      "EmbeddingAugmenter\n",
      "['Quel I cannot create, I do not understand.', 'What I cannot create, I do not realise.', 'What I cannot engender, I do not understand.', 'Whereof I cannot create, I do not understand.']\n",
      "DeletionAugmenter\n",
      "['I cannot create, I do not understand.', 'What I cannot create, I do not.', 'What I cannot create, do not understand.', 'What cannot create, I do not understand.']\n",
      "CharSwapAugmenter\n",
      "['Whaj I cannot create, I do not understand.', 'What I annot create, I do not understand.', 'What I cOannot create, I do not understand.', 'What I cannot create, I do not understnd.']\n"
     ]
    }
   ],
   "source": [
    "for augmenter in list_of_augmenters:\n",
    "    print(augmenter.__class__.__name__)\n",
    "    res = augmenter.augment(sentence)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eda_augmenter.augment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import transformations, contraints, and the Augmenter\n",
    "# from textattack.transformations import WordSwapMaskedLM\n",
    "# from textattack.transformations import WordSwapQWERTY\n",
    "# from textattack.transformations import CompositeTransformation\n",
    "# from textattack.transformations import Transformation\n",
    "\n",
    "# from textattack.constraints.pre_transformation import RepeatModification\n",
    "# from textattack.constraints.pre_transformation import StopwordModification\n",
    "\n",
    "# from textattack.augmentation import Augmenter\n",
    "\n",
    "# # Set up transformation using CompositeTransformation()\n",
    "# transformation = CompositeTransformation([WordSwapMaskedLM()])\n",
    "# # Set up constraints\n",
    "# constraints = [RepeatModification(), StopwordModification()]\n",
    "# # Create augmenter with specified parameters\n",
    "# augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.2, transformations_per_example=10)\n",
    "# s = 'What I cannot create, I do not understand.'\n",
    "# # Augment!\n",
    "# augmenter.augment(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "clare_augmenter = CLAREAugmenter(pct_words_to_swap=0.2,transformations_per_example=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What I cannot achieve, I do not understand.',\n",
       " 'What I cannot create, I do not know.',\n",
       " 'What I cannot grasp, I do not understand.',\n",
       " 'What I truly cannot create, I do not understand.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sentence = 'What I cannot create, I do not understand.'\n",
    "clare_augmenter.augment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('daproject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e49809d53688c26eba4712eaeabe2bade48dceb36fc5ac0f4a237b007fc1699d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
